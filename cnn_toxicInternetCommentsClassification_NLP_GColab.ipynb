{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_toxicInternetCommentsClassification_NLP_GColab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Classificar comentários da internet como tóxicos ou impróprios com uso de CNNs**"
      ],
      "metadata": {
        "id": "p4z1Axzf4Vwf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eikfzi8ZT_rW"
      },
      "source": [
        "# **Convolutional Neural Networks (CNN) applied to Natural Language Processing (NLP)**\n",
        "\n",
        "- Neste projeto, é utilizado um vocabulário (conjunto de palavras em inglês) previamente convertido em vetores de palavras.\n",
        "- Estes dados são combinados a uma base de dados contendo comentários de internet previamente rotulados em 6 rótulos de toxicidade, os quais não são mutuamente exclusivos. O comentário pode estar classificado (Resposta = 1) ou não estar classificado (Resposta = 0) naquele rótulo, de modo que temos 6 variáveis-respostas independentes (o comentário pode receber nenhum rótulo ou até 6 rótulos).\n",
        "\n",
        "Podemos aplicar as redes neurais convolucionais (CNNs) a sequências de \"word embeddings\".\n",
        "\n",
        "**A convolução é uma operação bastante geral e que pode ser aplicada a sinais de todos os tipos, não estando limitada ao uso em processamento de imagens**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaCkyg5CV5jF"
      },
      "source": [
        "# **Fazer upload de arquivos a partir de sistema de arquivos local**\n",
        "\n",
        "<code>files.upload</code> é um comando que retorna um dicionário Python com os arquivos incluídos no upload.\n",
        "O dicionário é indexado com o nome do arquivo e os valores são os dados enviados por upload."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFIGURAR Ambiente do COLAB:\n",
        "No menu superior, clique sobre a seta ao lado das barras RAM e Disco. No dropdown mostrado, selecione \n",
        "**\"Ver recursos\"**.\n",
        "\n",
        "No novo menu, utilize a barra de rolagem até chegar ao extremo inferior, e selecione a opção **\"Alterar o tipo de ambiente de execução\"**.\n",
        "\n",
        "Por fim, em **\"Acelerador de hardware\"**, selecione **\"GPU\"**."
      ],
      "metadata": {
        "id": "vYKaJI_AzXrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos carregar os arquivos com textos a serem classificados via CNN. Eles estão disponíveis nos links abaixo:\n",
        "\n",
        "Download the data:\n",
        "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
        "\n",
        "Download the word vectors:\n",
        "http://nlp.stanford.edu/data/glove.6B.zip\n"
      ],
      "metadata": {
        "id": "iRz2xRulXjqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os arquivos glove.6B possuem vetores de palavras já definidos. Como os arquivos são muito pesados, é melhor carregá-los primeiramente no Google Drive para posteriormente trazê-los ao ambiente do Colab (carregar diretamente no Colab levará tempo excessivo)."
      ],
      "metadata": {
        "id": "uLgpKJxR9wyL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2W5A2px3doP"
      },
      "source": [
        "# **Google Drive**\n",
        "\n",
        "É possível acessar os arquivos no Drive de várias maneiras. Por exemplo:\n",
        "- Montar o Google Drive na máquina virtual do ambiente de execução\n",
        "- Usar um wrapper ao redor da API, <a href=\"https://pythonhosted.org/PyDrive/\">como o PyDrive</a>\n",
        "- Usar a <a href=\"https://developers.google.com/drive/v3/web/about-sdk\">API REST nativa</a>\n",
        "\n",
        "\n",
        "\n",
        "Veja abaixo exemplos de cada um eles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u22w3BFiOveA"
      },
      "source": [
        "# **Montar o Google Drive localmente - Autorizar conexão do Google Colab aos arquivos do Google Drive**\n",
        "\n",
        "O exemplo abaixo mostra como montar o Google Drive no seu ambiente de execução usando um código de autorização, além de como gravar e ler arquivos nele. Depois de executado, você verá o novo arquivo &#40;<code>foo.txt</code>&#41; no <a href=\"https://drive.google.com/\">https://drive.google.com/</a>.\n",
        "\n",
        "Isto permite somente ler, gravar e mover arquivos. Para modificar de maneira programática as configurações de compartilhamento ou outros metadados, use uma das opções abaixo.\n",
        "\n",
        "<strong>Observação:</strong> ao usar o botão \"Montar Drive\" no navegador de arquivos, não é necessário usar nenhum código de autenticação para notebooks que tenham sido editados somente pelo usuário atual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "0be42d91-6279-4457-826e-3cfac06b76e7"
      },
      "source": [
        "#Esta célula é utilizada para conectar à conta do Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No menu à esquerda, clique sobre o ícone da pasta (\"**Arquivos**\"), e localize dentro da nova pasta \"drive\" a pasta do Google Drive contendo os arquivos desejados (clique na seta para expandir os dropdowns). \n",
        "\n",
        "Clique sobre a elipse (3 pontos à direita) do arquivo desejado e selecione a opção \"**Copiar caminho**\" para copiar os endereços de cada um dos arquivos que serão analisados.\n",
        "\n",
        "Note que o caminho será diferente para cada usuário do Google Drive."
      ],
      "metadata": {
        "id": "SSQaZ5umC2h_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Endereços:\n",
        "\n",
        "glove.6B.50d.txt: /content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/glove.6B.50d.txt\n",
        "\n",
        "glove.6B.100d.txt: /content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/glove.6B.100d.txt\n",
        "\n",
        "glove.6B.200d.txt: /content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/glove.6B.200d.txt\n",
        "\n",
        "glove.6B.300d.txt: /content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/glove.6B.300d.txt\n",
        "\n",
        "sample_submission.csv: /content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/sample_submission.csv\n",
        "\n",
        "test.csv: /content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/test.csv\n",
        "\n",
        "test_labels.csv: /content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/test_labels.csv\n",
        "\n",
        "train.csv: /content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/train.csv"
      ],
      "metadata": {
        "id": "t2mVIAh0f0te"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importar bibliotecas para análise**"
      ],
      "metadata": {
        "id": "sLmPin6ig-eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://deeplearningcourses.com/c/deep-learning-advanced-nlp\n",
        "from __future__ import print_function, division\n",
        "from builtins import range\n",
        "# Note: you may need to update your version of future\n",
        "# sudo pip install -U future\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "k5LC3b1ag8dX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As bibliotecas \"os\" e \"sys\" possibilitam ler e fundir (merge) arquivos, como será visto adiante."
      ],
      "metadata": {
        "id": "pOOpjPd-g0e3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizer**: transformar uma sentença (uma grande string contendo palavras e pontuação) em uma lista de strings, na qual cada elemento da lista é chamado de token.\n",
        "\n",
        "Tokenização é um aspecto chave e mandatório do processamento de textos. Os tokens são os blocos de construção do processamento de linguagem natural, utilizados tanto em métodos tradicionais quanto nos mais modernos algoritmos de deep learning.\n",
        "\n",
        "A tokenização consiste em separar um trecho de texto em unidades menores (tokens), as quais podem ser palavras, caracteres, ou subpalavras. A forma mais comum de formar tokens é a separação por meio da identificação de espaços em branco que demarcam a separação entre as palavras.\n",
        "\n",
        "Assim, o token geralmente será uma palavra, mas pode ser pontuação, apóstrofe, parte de uma contração, etc, dependendo da estratégia de tokenização aplicada. Portanto, a tokenização pode ser vista como uma estratégia de split de strings."
      ],
      "metadata": {
        "id": "ho1kCOvKqaTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**pad_sequences**: nós precisamos deste comando porque desejamos que todas as nossas sequências apresentem o mesmo comprimento. Porém, quando carregamos a sequência no ambiente, elas apresentam diferentes comprimentos.\n",
        "\n",
        "Assim, nós adicionamos o padding para obter uma saída \"reta\"."
      ],
      "metadata": {
        "id": "qcMO-wNs7VKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configurações das redes neurais e do processamento de texto**"
      ],
      "metadata": {
        "id": "LhqIspfRhvS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some configuration\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "eI_tusKJh0L4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAX_SEQUENCE_LENGTH**: definimos em 100 por se tratarem de comentários de internet. Este parâmetro pode ser modificado: por exemplo, após carregar todos os dados, define-se este parâmetro como sendo igual ao maior comprimento presente. Outra estratégia é verificar o histograma dos comprimentos de comentários para averiguar se o parâmetro escolhido faz sentido.\n",
        "\n",
        "**MAX_VOCAB_SIZE: tamanho do vocabulário de aprendizagem** (total de palavras do vocabulário). Se houver mais que MAX_VOCAB_SIZE = 20000, o vocabulário será truncado em 20.000 palavras. Experimentos mostraram que um falante de inglês nativo conhece, em média, cerca de 20000 palavras. Embora estes resultados sejam controversos e provavelmente superestimados, este é um valor popularmente adotado para este parâmetro.\n",
        "\n",
        "**EMBEDDING_DIM**: comprimento de cada vetor de palavras (word vector). Você não pode escolher qualquer comprimento quando trabalhando com modelos pré-treinados. Isto porque os *modelos pré-treinados costumam vir com determinados valores de comprimento de vetor de palavras fixados*. Aqui, usaremos vetores de comprimento 50 ou 100, mas comprimentos iguais a 200 e 300 também estão disponíveis nos arquivos."
      ],
      "metadata": {
        "id": "bF1ceq1F8YOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vamos criar um dicionário vazio, chamado word2vec** \n",
        "Este dicionário armazenará os dados já pré-configurados, i.e., palavras que já foram convertidas em vetores numéricos, e que estão disponíveis nas bases glove.6B.\n",
        "\n",
        "- O comprimento dos vetores de palavras será o definido e armazenado em EMBEDDING_DIM.\n",
        "- O dicionário possui como estrutura: a palavra como a chave (key); e o vetor de palavras (word vector) como o valor correspondente.\n",
        "- A nomenclatura word2vec vem de \"word pointing to vector\".\n",
        "- Os arquivos glove.6B consistem em txt contendo a cada linha uma palavra seguida dos valores das componentes dos vetores, separados por espaços em branco.\n",
        "- Assim, nós: 1) carregamos uma linha; 2) dividimos (split) as linhas em tokens; 3) tomamos o primeiro token como sendo a palavra; 4) tomamos os demais tokens como o vetor; 5) convertemos o vetor em um NumPy array; 6) e, por fim, salvamos cada array no nosso dicionário."
      ],
      "metadata": {
        "id": "0d6Xy9QThLJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ATENÇÃO**\n",
        "\n",
        "O endereço dos arquivos deve ser inserido com o número correto de espaçamentos. A inclusão de espaços em branco a mais no começo e no fim resultará em erro de processamento."
      ],
      "metadata": {
        "id": "6aNIdLyMiRB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load in pre-trained word vectors\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "#dicionário em branco, a ser povoado\n",
        "\n",
        "with open(os.path.join('/content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
        "  # is just a space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MEIQjDghbd4",
        "outputId": "d8f60afc-4d20-4232-fd22-7200c8ffaa5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Não imprima o dicionário word2vec! Devido ao seu tamanho elevado, sobrecarregará a visualização do notebook."
      ],
      "metadata": {
        "id": "gniBdfTfiqaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que ainda não começamos o treinamento das CNNs. O que fizemos aqui foi abrir uma série de arquivos de texto previamente carregados no Google Drive (arquivos contendo dados pré-treinados de palavras convertidas em vetores numéricos). Após abri-los com o comando with open, manipulamos as strings para que os dados povoassem um dicionário vazio."
      ],
      "metadata": {
        "id": "4FNQtI3ukCuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caso estivesse usando um ambiente offline, e não o Google Colab, o seguinte código deveria ser utilizado:\n",
        "\n",
        "```\n",
        "# load in pre-trained word vectors\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "with open(os.path.join('../large_files/glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
        "  # is just a space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "VG-Xb5jvk1mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que o trecho `glove.6B.%sd.txt' % EMBEDDING_DIM`\n",
        "\n",
        "faz com que todos os arquivos com o número %s = EMBEDDING_DIM sejam lidos.\n"
      ],
      "metadata": {
        "id": "5bwdfRA9lYxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vamos carregar os dados de treinamento, formados pelos comentários de internet a serem classificados em \"toxicidade\"**"
      ],
      "metadata": {
        "id": "xyY7kIV2ILVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare text samples and their labels\n",
        "print('Loading in comments...')\n",
        "\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/train.csv\")\n",
        "sentences = train[\"comment_text\"].fillna(\"DUMMY_VALUE\").values\n",
        "possible_labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "targets = train[possible_labels].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9FurwavIMCI",
        "outputId": "e315467a-c7a2-4c43-a189-c040a49ab2bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading in comments...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que, como ocorre para qualquer CSV ou arquivo Excel, seja ele carregado no ambiente Python offline, no Google Drive, ou diretamente no Google Colab, **precisamos invocar as funções do Pandas read_csv ou read_excel para converter o arquivo em um objeto do tipo dataframe**.\n"
      ],
      "metadata": {
        "id": "Gzp-Y67gJSxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos verificar o aspecto geral do dataframe de treinamento:"
      ],
      "metadata": {
        "id": "grdwAmgDKLfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "cThmg_0KKJak",
        "outputId": "03dea381-5f79-409d-ed47-ff70066a0c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1e8188cb-ddbd-492f-9ed3-0c49ba65a40a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e8188cb-ddbd-492f-9ed3-0c49ba65a40a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e8188cb-ddbd-492f-9ed3-0c49ba65a40a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e8188cb-ddbd-492f-9ed3-0c49ba65a40a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "m8ro5VEsUAjb",
        "outputId": "97ab9d4e-558e-4ebe-f6c2-f4be039298fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6d201b1e-9aa5-45a2-8b7f-c949bb990c05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.095844</td>\n",
              "      <td>0.009996</td>\n",
              "      <td>0.052948</td>\n",
              "      <td>0.002996</td>\n",
              "      <td>0.049364</td>\n",
              "      <td>0.008805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.294379</td>\n",
              "      <td>0.099477</td>\n",
              "      <td>0.223931</td>\n",
              "      <td>0.054650</td>\n",
              "      <td>0.216627</td>\n",
              "      <td>0.093420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d201b1e-9aa5-45a2-8b7f-c949bb990c05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d201b1e-9aa5-45a2-8b7f-c949bb990c05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d201b1e-9aa5-45a2-8b7f-c949bb990c05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               toxic   severe_toxic  ...         insult  identity_hate\n",
              "count  159571.000000  159571.000000  ...  159571.000000  159571.000000\n",
              "mean        0.095844       0.009996  ...       0.049364       0.008805\n",
              "std         0.294379       0.099477  ...       0.216627       0.093420\n",
              "min         0.000000       0.000000  ...       0.000000       0.000000\n",
              "25%         0.000000       0.000000  ...       0.000000       0.000000\n",
              "50%         0.000000       0.000000  ...       0.000000       0.000000\n",
              "75%         0.000000       0.000000  ...       0.000000       0.000000\n",
              "max         1.000000       1.000000  ...       1.000000       1.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A etapa seguinte consiste em extrair o que são de fato os comentários.\n",
        "- Nesta base de dados, os comentários estão dispostos na forma: coluna; comentário; texto.\n",
        "- Na linha a seguir, note que não foi utilizado o dropna, que remove as linhas contendo missing values. Foi utilizado o comando **\"fillna\"**, o qual confere o valor \"DUMMY_VALUE\" às entradas sem valores:\n",
        "```\n",
        "sentences = train[\"comment_text\"].fillna(\"DUMMY_VALUE\").values\n",
        "```\n",
        "- Note ainda que o comando **.values** faz com que o NumPy array \"sentences\" armazene apenas os valores do campo \"comment_text\" dos dados de treino (já com o preenchimento dos missing values).\n",
        "- A lista \"possible_labels\" define como os comentários poderão ser rotulados. Note que as classificações não são mutuamente exclusivas: um comentário pode ser classificado em mais de um rótulo, de modo que cada um deles é uma resposta binária **(o comentário pertence = 1; ou não pertence = 0 àquela classe)** independente.\n",
        "- Na realidade, esta lista não apresenta nomes que serão fornecidos ao dataframe de treino. Ela apenas discrimina quais dados do dataframe serão utilizados como targets.\n",
        "- Esta lista é passada como argumento da linha a seguir. Nela, **o comando .values faz com que o dataframe \"target\" armazene os valores das colunas dos dados de treinamento, desde que estas colunas estejam entre as discriminadas na lista**."
      ],
      "metadata": {
        "id": "gSN9M-2cOigy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Aplicar o método keras.tokenizer para conversão das sentenças em números inteiros**"
      ],
      "metadata": {
        "id": "9RYyO1y2fHGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta é mais uma etapa de pré-processamento textual. Note que, até aqui, ainda temos uma lista que lembra uma serra, já que cada sentença ainda apresenta um comprimento diferente.\n",
        "- Logicamente, a lista ainda é constituída por strings, o que não é processável pelas redes neurais (as redes neurais exigem que as strings sejam convertidas em valores numéricos).\n",
        "- As strings ainda contêm os comentários completos, ou seja, ainda não foram tokenizadas.\n",
        "- Devemos aplicar o **método tokenizer da biblioteca keras** para resolver estes problema: o **keras.tokenizer** converte as sentenças em listas de tokens e, a seguir, converte estas listas em números inteiros.\n",
        "- Estes números inteiros serão usados para indexar o **word embedding** (a matriz contendo os vetores das palavras, na qual cada linha da matriz corresponde ao vetor numérico de uma palavra)."
      ],
      "metadata": {
        "id": "MlsGiblYhBA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the sentences (strings) into integers\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)"
      ],
      "metadata": {
        "id": "PKdtjKzHZwDa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Caracterização das sequências de texto obtidas e convertidas em inteiros**"
      ],
      "metadata": {
        "id": "3c3ZXakVf4uO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos caracterizar os comentários, agora que foram tokenizados e convertidos em números inteiros"
      ],
      "metadata": {
        "id": "okvHwDWCik9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max sequence length:\", max(len(s) for s in sequences))\n",
        "print(\"min sequence length:\", min(len(s) for s in sequences))\n",
        "s = sorted(len(s) for s in sequences)\n",
        "print(\"median sequence length:\", s[len(s) // 2])\n",
        "\n",
        "print(\"max word index:\", max(max(seq) for seq in sequences if len(seq) > 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHSDzHJ0fwLo",
        "outputId": "4d32120a-18fb-4364-adce-a30897384215"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max sequence length: 1400\n",
            "min sequence length: 0\n",
            "median sequence length: 35\n",
            "max word index: 19999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que aqui as sequências são, na realidade, os comentários, os quais podem conter mais de uma sentença. Porém, para os propósitos desta análise em particular, é mais simples chamar a string completa do comentário de sentença."
      ],
      "metadata": {
        "id": "Ku9HnflEgWr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Associar cada palavra a uma linha (vetor de palavras) do word embedding**"
      ],
      "metadata": {
        "id": "7nnU3cv_zLle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que as sentenças foram convertidas em números inteiros, surge a pergunta sobre a qual palavra cada número inteiro corresponde.\n",
        "- Além disso, desejamos saber qual linha do word embedding pertence a cada palavra.\n",
        "- Lembrando o que é o word embedding: **word embedding é a matriz dos vetores das palavras. Cada linha do word embedding representa o vetor numérico associado a cada palavra**. \n",
        "- Indexar aqui significa encontrar o índice do vetor (ou seja a linha do word embedding) que descreve cada uma das palavras tokenizadas."
      ],
      "metadata": {
        "id": "_HCjCbO3pcbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para isso, precisamos de um **mapeamento palavra-para-índice** (word to index mapping).\n",
        "- Neste mapa, a chave (key) será a palavra, e o índice será o valor correspondente.\n",
        "- **O keras.tokenizer mantém esta informação de mapeamento em um atributo chamado word_index**."
      ],
      "metadata": {
        "id": "agUpcMQSypG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get word -> integer mapping\n",
        "word2idx = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKZWevVzzdWc",
        "outputId": "61f2d6af-03db-4d92-c63e-0288de888f98"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 210337 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que o mesmo atributo é utilizado para nos informar **quantas palavras foram encontradas no dataset: este valor será igual ao tamanho (length) do dicionário obtido**."
      ],
      "metadata": {
        "id": "LzHXzzm_zt27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Limitar comprimento das sequências de texto com o método pad_sequences**"
      ],
      "metadata": {
        "id": "Vn38u-CS0oJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste momento, ainda temos um problema com nossos dados: os arrays continuam com tamanhos diferentes, formando um aspecto de serra.\n",
        "\n",
        "- Para resolver este problema, a próxima etapa de pré-processamento será aplicar o **método pad_sequences, com comprimento máximo definido previamente na variável MAX_SEQUENCE_LENGTH**."
      ],
      "metadata": {
        "id": "T4x1rulG0IKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pad sequences so that we get a N x T matrix\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WVLgpwr0z2X",
        "outputId": "bce2f8d1-97da-4482-c72c-1098a996c678"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (159571, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta etapa é particularmente importante porque a biblioteca **Keras trabalha com sequências de dimensões constantes**.\n",
        "- O formato do tensor de dados representa a dimensão da matriz (N x T) obtida. Limitamos a 100 o máximo comprimento da sequência de textos.\n",
        "- N = contagem de elementos, que foi anteriormente observada na linha **count** do dataframe gerado como** train.describe()**;\n",
        "- T será o máximo comprimento permitido para o vetor de palavras (máximo possível de colunas), definido como **MAX_SEQUENCE_LENGTH = 100**."
      ],
      "metadata": {
        "id": "QplYu8hQ1A-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que, para que todas as sequências tenham o mesmo comprimento, **caso o vetor tenha um comprimento menor que MAX_SEQUENCE_LENGTH, o método pad_sequences adicionará vários números zero ao fim dele** até que ele atinja o comprimento máximo."
      ],
      "metadata": {
        "id": "F0MLO-JS2GkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma questão que surge é como saber se o vetor ao qual foram adicionados os números zero não passou a ser igual a um outro vetor de palavras previamente definido no nosso vocabulário.\n",
        "- Esta é uma questão válida, já que, ao construir o dicionário que correlaciona as palavras aos índices, nós utilizamos o zero para representar uma das palavras.\n",
        "- Porém, **neste caso em particular, Keras inicia a indexação pelo número 1, e apenas utiliza o zero como um valor especial reservado para a operação de padding**.\n",
        "- Desde que você **permaneça no ecossistema Keras durante as etapas de pré-processamento de texto**, a adição dos números zero não será um problema."
      ],
      "metadata": {
        "id": "WaFn6gAcA979"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pré-carregar a matriz de incorporação (\"embedding matrix\") que será utilizada pela rede neural**"
      ],
      "metadata": {
        "id": "UxDgi89rCrAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No começo deste notebook, carregamos vetores de palavras previamente definidos, contidos no arquivo glove.\n",
        "\n",
        "- A primeira coisa a fazer agora é verificar o número de palavras que será realmente utilizado como vocabulário da rede neural.\n",
        "\n",
        "Este valor é simplesmente o mínimo entre MAX_VOCAB_SIZE = 20000, e o **comprimento (total de palavras) do dicionário** palavra-para-índice (\"*word to index dictionary*\") **somado a 1**.\n",
        "\n",
        "Explicação:\n",
        "- Lembre-se que definimos nos parâmetros de configuração inicial:\n",
        "```\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "```\n",
        "\n",
        "- Entretanto, o número de palavras no dataset pode ser menor que 20.000. Neste caso, nós não queremos que sejam criados 20.000 vetores de palavras, mas sim o **menor número possível de vetores** (ou seja, armazenaremos menos que 20000 palavras).\n",
        "\n",
        "- Por sua vez, o número de palavras pode ser superior a 20000. Nesta situação, **desejamos truncar os dados (o vocabulário) para que reste apenas MAX_VOCAB_SIZE = 20000 vetores**."
      ],
      "metadata": {
        "id": "WuDiTn4z1c_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwcfLgYb21qP",
        "outputId": "92c52b9c-e357-4fd8-87a8-63cc1baa432d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filling pre-trained embeddings...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O trecho acima:\n",
        "\n",
        "1) Verifica o total de vetores de palavras presente no vocabulário (o comprimento/dimensão do dicionário);\n",
        "\n",
        "2) Compara este valor com MAX_VOCAB_SIZE.\n",
        "- Se o tamanho do vocabulário for menor que MAX_VOCAB_SIZE, então MAX_VOCAB_SIZE é igualado ao tamanho do dicionário + 1 para que possamos trabalhar com o menor número possível de vetores de palavras (i.e., com menos palavras);\n",
        "- Se a dimensão for maior que MAX_VOCAB_SIZE, truncamos o vocabulário de modo que ele terá apenas MAX_VOCAB_SIZE = 20000 palavras."
      ],
      "metadata": {
        "id": "J2S_jak_6gYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que **precisamos somar 1** em\n",
        "\n",
        "```\n",
        "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
        "```\n",
        "**Porque, como visto, a biblioteca Keras inicia a indexação dos vetores de palavras em 1**, reservando o valor zero para as operações de padding.\n",
        "\n",
        "Assim, se tivermos 20000 palavras, o índice da última palavra será efetivamente 20000, e não 19999 (índice esperado se a numeração começasse em zero, como comumente ocorre com as listas em Python).\n",
        "\n",
        "Assim, caso deseje utilizar o índice para indexar um array, é necessário acrescentar um elemento. Isso porque, em Python, a numeração dos elementos dos arrays, assim como das listas, começa em zero.\n"
      ],
      "metadata": {
        "id": "9PnmgbKz8_Y4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outra questão que pode surgir é: uma vez que tomamos o mínimo entre 20000 e o tamanho do vocabulário, o que ocorrerá se houver índices no array de dados maiores que 20000?\n",
        "\n",
        "De fato, caso tente indexar um array por um número maior ou igual ao seu comprimento, o resultado será uma exceção (\"*exception error*\").\n",
        "\n",
        "Felizmente, esta questão já foi resolvida anteriormente durante a criação do tokenizer:\n",
        "```\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "```\n",
        "Como utilizamos MAX_VOCAB_SIZE como um dos argumentos do método Tokenizer, **Keras já definiu que estes índices, caso existam, estarão fora dos tolkens do vocabulário**.\n",
        "\n",
        "- OBS: comumente encontramos estas situações que foram assinaladas como fora dos tolkens referenciadas pela abreviatura **OOV** (\"*out of vocabulary*\").\n",
        "- Outra abreviação comumente encontrada em comentários de códigos é **UNK, referente a unknown**."
      ],
      "metadata": {
        "id": "GLrxko-a-Qqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Criação da matriz embedding**"
      ],
      "metadata": {
        "id": "WqRrzMIHA1qJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A última etapa do pré-processamento do texto consiste em criar uma matriz V x D de zeros, que será o **embedding**. V é simplesmente o número de palavras num_words, o qual já calculamos, e D é a dimensão do embedding, EMBEDDING_DIM.\n",
        "\n",
        "A seguir, criamos um loop que avalie cada palavra do dicionário palavras-para-índices (\"word to index dictionary\").\n",
        "\n",
        "- **Se o índice for menor que o MAX_VOCAB_SIZE** (já corrigido para o caso de haver menos palavras que o definido nos parâmetros), **então ele deverá estar no embedding**.\n",
        "- Esta etapa consiste, então, em uma tentativa de recuperar o vetor de palavras pré-treinado do dicionário de palavras.\n",
        "- Lembre-se que os **vetores de palavras pré-configurados vêm de uma fonte (arquivos glove) diferente da fonte dos comentários classificados como tóxicos e utilizados como dados de treinamento** (arquivo train.csv). \n",
        "- Como os dados de treinamento é que são utilizados para construir o dicionário, **é possível que determinados vetores de palavras pré-treinados não sejam encontrados no dicionário** (as duas fontes de dados, glove e train, não são necessariamente equivalentes).\n",
        "\n"
      ],
      "metadata": {
        "id": "8Gq6QpZ6A6dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word2idx.items():\n",
        "  if i < MAX_VOCAB_SIZE:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all zeros.\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "rB9BnSZbDy3A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repare que utilizamos o método **get** em:\n",
        "\n",
        "```\n",
        "word2vec.get(word)\n",
        "```\n",
        "Caso a chave (key) correspondente a um dos vetores de palavras pré-configurados não seja encontrada no dicionário (ou seja, caso aquela palavra não esteja presente no vocabulário de treinamento), **o método get simplesmente retorna um valor nulo como chave do dicionário, ao invés de gerar uma exceção, como ocorreria ao se tentar indexar um array ou lista**.\n",
        "\n",
        "- O trecho acima também verifica, na sequência, se o vetor é nulo, em:\n",
        "```\n",
        " if embedding_vector is not None:\n",
        "```\n",
        "- Caso o vetor não seja nulo, ele é assinalado à matriz de embedding na localização apropriada.\n",
        "\n"
      ],
      "metadata": {
        "id": "dae0HeWVEEmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Construção e avaliação da CNN**"
      ],
      "metadata": {
        "id": "jo3lUR33FmFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As etapas anteriores constituíram o pré-processamento do texto necessário à construção do modelo de redes neurais.\n",
        "\n",
        "Estas etapas constituem cerca de 90% do código do notebook, e **muitas delas são genéricas e aplicáveis a diversos exemplos de NLP**."
      ],
      "metadata": {
        "id": "4ehG4P03F0Nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Criação da camada de embedding**"
      ],
      "metadata": {
        "id": "bqJDGfflnC7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A criação da camada de embedding consiste em simplesmente criar um objeto do tipo \"**Embedding**\"."
      ],
      "metadata": {
        "id": "o-A-zvQZnKkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load pre-trained word embeddings into an Embedding layer\n",
        "# note that we set trainable = False so as to keep the embeddings fixed\n",
        "embedding_layer = Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=MAX_SEQUENCE_LENGTH,\n",
        "  trainable=False\n",
        ")\n",
        "\n",
        "\n",
        "print('Building model...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PLJdSb0BRkS",
        "outputId": "ab0512cf-6be0-437e-aa05-67c824342f81"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os dois primeiros argumentos para construção da camada de embedding são o total de palavras \"**num_words**\" (tamanho do vocabulário); e a dimensão do embedding \"EMBEDDING_DIM\".\n",
        "\n",
        "- A seguir, vem o argumento **\"weights\"**: nós passamos como argumento justamente **a matriz de embedding que construímos nas etapas anteriores**.\n",
        "- O argumento **\"input_length\"** informa ao objeto embedding **quão longas nossas sequências serão. Este valor foi fornecido inicialmente em MAX_SEQUENCE_LENGTH**.\n",
        "- No último argumento (\"**trainable**\") fornecemos o valor booleano **False pois não desejamos que os pesos sejam atualizados durante o procedimento de treino (estamos utilizando vetores pré-treinados** da base glove.6B).\n",
        "- Logicamente, é permitido realizar a atualização, modificando-se o parâmetro para True. Porém, isto representará maior custo computacional e, possivelmente, um tempo longo de treinamento."
      ],
      "metadata": {
        "id": "6HTw3S09naOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Construção do restante do modelo de redes neurais convolucionais (CNNs)**"
      ],
      "metadata": {
        "id": "cMUJb5K7pcel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temos aqui um tensor de dados (variável \"data\") constituídos pelos comentários a serem classificados. É uma matriz N x T contendo os índices das palavras, na qual N é o total de amostras/dados e T é o comprimento da sequência.\n",
        "- Temos também a variável \"target\", que representa os rótulos atribuídos a cada sequência. É uma matriz de dimensão N x 6, já que definimos 6 rótulos possíveis.\n",
        "- Além disso, temos a matriz de embedding, de dimensão V x D, à qual já assinalamos alguns vetores de palavras. V é o tamanho do vocabulário e D é a dimensão do embedding.\n"
      ],
      "metadata": {
        "id": "J4QALznJ_EL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para construção da rede neural em Keras, o primeiro requisito é criar o objeto de input.\n",
        "\n",
        "- Devemos especificar cada uma das dimensões, exceto o tamanho da amostra, o qual já está implícito.\n",
        "- Como visto, o input usará como argumento um tensor de dados de dimensão N x T, onde N = contagem de elementos (tamanho de amostra, implícito), e T = máximo comprimento permitido para o vetor de palavras = **MAX_SEQUENCE_LENGTH = 100**.\n",
        "- Assim, precisamos apenas fornecer T = MAX_SEQUENCE_LENGTH como argumento de criação do objeto de input.\n",
        "\n",
        "A seguir, utilizamos este input como argumento da camada de embedding que criamos a pouco."
      ],
      "metadata": {
        "id": "RZQYAdSApy1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train a 1D convnet with global maxpooling\n",
        "input_ = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "x = embedding_layer(input_)"
      ],
      "metadata": {
        "id": "yfvKBK3ApqpI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repare no trecho:\n",
        "```\n",
        "x = embedding_layer(input_)\n",
        "```\n",
        "Aqui está sendo utilizado o API funcional Keras (\"Keras functional API\") para passar o input como argumento da camada de embedding.\n",
        "- Isto torna a sintaxe ligeiramente diferente da encontrada em outros códigos Keras que usam o modelo sequencial.\n",
        "\n"
      ],
      "metadata": {
        "id": "N2KcUVwNRah9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = Conv1D(128, 3, activation='relu')(x)\n",
        "x = MaxPooling1D(3)(x)\n",
        "x = Conv1D(128, 3, activation='relu')(x)\n",
        "x = MaxPooling1D(3)(x)\n",
        "x = Conv1D(128, 3, activation='relu')(x)\n",
        "x = GlobalMaxPooling1D()(x)"
      ],
      "metadata": {
        "id": "rd8F2SqXSLXZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste trecho, os dados são transferidos da camada de embedding para **três camadas sequenciais de convolução de de Max Pooling**. Códigos em Keras comumente utilizam uma mesma variável denominada \"x\" para vários objetos e operações em sequência.\n",
        "\n",
        "Repare que a diferença para o procedimento de uso das redes neurais convolucionais aplicadas em visão computacional é basicamente o fato de que, **para processamento de imagens, utilizamos uma camada de convolução bidimensional (\"Conv2D\"), enquanto que aqui aplicamos a camada unidimensional (\"Conv1D\")**.\n",
        "- Isto ocorre porque as sequências de palavras, logicamente, estão em vetores unidimensionais, e não em duas dimensões, como as imagens planas.\n",
        "\n"
      ],
      "metadata": {
        "id": "H2UuD1IESNUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Camada de agrupamento (\"Pooling layer\")**\n",
        "\n",
        "https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/\n",
        "\n",
        "A explicação a seguir refere-se ao caso mais geral das redes neurais convolucionais com 2 dimensões, aplicadas ao processamento de imagens. Como o caso bidimensional é uma extensão do unidimensional, as mesmas considerações são válidas para o processamento de textos por NLP.\n",
        "\n",
        "As camadas convolucionais em uma rede neural convolucional aplicam sistematicamente os filtros aprendidos às imagens de input de modo a criar mapas de características (\"**feature maps**\") que resumem a presença daquelas características da imagem de entrada.\n",
        "\n",
        "As camadas convolucionais se mostram bastante eficientes, e o empilhamento (\"stacking\") de camadas convolucionais em modelos deep learning permitem que as camadas mais próximas ao input aprendam características de baixo nível (\"low-level features\"), tais como linhas. Enquanto isso, as camadas mais profundas do modelo aprendem características de ordem mais elevada e mais abstratas, tais como a forma ou objetos específicos.\n",
        "\n",
        "**Uma limitação do mapa de características das camadas convolucionais é que eles gravam a posição precisa das características de input**. Isto significa que pequenos deslocamentos na posição daquela característica na imagem de input resultarão em um mapa de características diferente. Isto pode ocorrer mesmo com modificações mínimas da imagem, tais como corte, rotação, deslocamento (\"shifting\"), ou espelhamento da imagem.\n",
        "\n",
        "Uma metodologia comumente empregada para solucionar este problema no processamento de sinais é chamada redução de amostragem (\"down sampling\"). Nesta estratégia, **uma versão de resolução mais baixa do sinal de entrada é criada, e tal versão contém os maiores ou mais importantes elementos estruturais, mas não os detalhes finos que podem não ser tão úteis na tarefa de classificação**.\n",
        "\n",
        "O \"down sampling\" pode ser obtido com as camadas convolucionais por meio da alteração do caminho de convolução ao qual se submete a imagem. **Uma abordagem comum e mais robusta é a utilização de uma camada de agrupamento (\"pooling layer\")**.\n",
        "\n",
        "A camada de agrupamento é uma nova camada adicionada após a camada convolucional. Mais especificamente, **uma não-linearidade (e.g. ReLU) é aplicada aos mapas de características obtidos como saída da camada convolucional, e estes novos mapas são utilizados como inputs da camada de agrupamento**. Assim, a sequência de camadas e operações do modelo segue o esquema:\n",
        "\n",
        "- Imagem de input;\n",
        "- Camada Convolucional;\n",
        "- Não-linearidade;\n",
        "- Camada de agrupamento.\n",
        "\n",
        "**A adição da camada de agrupamento após a camada convolucional é um padrão comumente empregado para ordenamento de camadas em uma rede neural convolucional**, e pode ser repetido uma ou mais vezes em um modelo.\n",
        "\n",
        "A camada de agrupamento opera separadamente sobre cada mapa de características de modo a criar um novo conjunto com o mesmo número de mapas de características agrupadas.\n",
        "\n",
        "O agrupamento envolve a seleção de uma operação de agrupamento, de forma muito semelhante a um filtro aplicado a mapas de características. As dimensões da operação ou filtro de agrupamento são menores que o tamanho do mapa de características. Quase sempre se aplica 2x2 pixels com um caminho de 2 pixels.\n",
        "\n",
        "**Isto significa que a camada de agrupamento sempre reduz a dimensão de um mapa de características por um fator igual a 2**. \n",
        "\n",
        "**Assim, cada dimensão é reduzida pela metade**, reduzindo o total de pixels (imagem bidimensional) ou os valores do mapa de características a 1/4 do seu tamanho original. Por exemplo, uma camada de agrupamento aplicada a um mapa de características 6x6 (36 pixels) resultará em um mapa de características agrupado (saída) de dimensões 3x3 (9 pixels).\n",
        "\n",
        "**A operação de agrupamento não é aprendida, mas sim especificada**. Duas funções comumente empregadas para o agrupamento são:\n",
        "\n",
        "- **\"Average Pooling\"**: calcula o valor médio para cada fragmento (\"patch\") do mapa de características.\n",
        "- **\"Maximum Pooling\"**: calcula o valor máximo para cada fragmento (\"patch\") do mapa de características.\n",
        "\n",
        "O resultado da utilização de uma camada de agrupamento e da criação de amostras reduzidas ou agrupadas dos mapas de características é a **obtenção de uma versão resumida das características a serem detectadas no input**.\n",
        "\n",
        "Esta versão resumida é útil porque **pequenas mudanças de posição de uma determinada característica na entrada (detectada pela camada convolucional) resultarão em um mapa de características agrupadas (\"pooled\") com a característica na mesma localização**. \n",
        "\n",
        "Esta capacidade fornecida pela \"pooling layer\" é chamada de **invariância do modelo à translação local**."
      ],
      "metadata": {
        "id": "W_hNdKjncA_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No trecho\n",
        "\n",
        "```\n",
        "x = Conv1D(128, 3, activation='relu')(x)\n",
        "```\n",
        "Repare que a não linearidade aplicada é dada pela função de ativação ReLU.\n",
        "\n",
        "- Além disso, **a terceira e última operação de \"Maximum Pooling\" é chamada de Global, e é a única sem parâmetros de entrada**:\n",
        "\n",
        "```\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "```\n",
        "**Global Maximum Pooling**: a utilização desta operação indica que temos uma série temporal, mas não nos importamos com o quão longa esta série é. **Apenas tomamos o maior valor da série temporal em cada dimensão**.\n",
        "\n",
        "- Repare que os inputs são matrizes de dimensões T x M, onde T é o comprimento da sequência e M é o total de propriedades (\"features\"). Após aplicarmos o Global Maximum Pooling, a saída será de comprimento M.\n",
        "\n",
        "```\n",
        "T x M --> GlobalMaxPooling --> M\n",
        "```\n",
        "- Esta operação pode ser entendida como **a seleção de qual ponto do intervalo de tempo foi mais importante para o cálculo da saída**.\n",
        "- Assim, nós percorremos toda a série temporal e, com isso, descobrimos quando ocorreu a característica mais importante.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AEfLTLwVp6YZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Camadas densas (\"dense layers\")**\n",
        "\n",
        "Para completar o modelo, submetemos a saída da última camada de pooling a um par de camadas densas (assim como em redes neurais artificiais simples). Na segunda delas, modificamos a função de ativação para a sigmoide, possibilitando a captura de outros aspectos de não-linearidade."
      ],
      "metadata": {
        "id": "4AnxC0vktxjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = Dense(128, activation='relu')(x)\n",
        "output = Dense(len(possible_labels), activation='sigmoid')(x)"
      ],
      "metadata": {
        "id": "M0Q-0pY3rI0h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O motivo de desejarmos utilizar aqui a função sigmoide é que **estamos realizando 6 classificações binárias, uma para cada um dos rótulos de toxicidade propostos**.\n",
        "- Lembre-se que cada comentário pode ter de 1 a 6 rótulos, ou mesmo nenhum rótulo (situação na qual a resposta é igual a zero para todas as 6 respostas).\n",
        "\n",
        "Com esta etapa, concluímos a construção do modelo, **sendo a camada de saída do modelo assinalada à variável \"output\" em**:\n",
        "\n",
        "```\n",
        "output = Dense(len(possible_labels), activation='sigmoid')(x)\n",
        "```\n",
        "- Repare que a saída do modelo, \"output\", leva um argumento anterior à última função de ativação: a quantidade de variáveis de saída. **Como temos uma resposta correspondente a cada rótulo, o primeiro argumento é igual ao comprimento (total de elementos) da lista que armazena os rótulos possíveis**.\n",
        "\n",
        "Por fim, vale destacar que **cada uma das operações de convolução, Pooling, ou Dense corresponde a uma camada da rede neural construída**."
      ],
      "metadata": {
        "id": "fCuD3Z5mvP7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Criação de um objeto do modelo (\"model object\")**\n",
        "\n",
        "Agora que concluímos a construção do modelo, podemos assinalar ele a um objeto que armazenará as suas principais informações.\n",
        "\n",
        "- **A função construtora (\"constructor\") deste objeto utiliza como primeiro argumento o input, e a saída (\"output\") como segundo argumento**."
      ],
      "metadata": {
        "id": "DCGAMPaCwIYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_, output)"
      ],
      "metadata": {
        "id": "xTvEzGBpwyQh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que o objeto que armazena o modelo foi denominado \"model\"."
      ],
      "metadata": {
        "id": "KchbpYrnw0Yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compilar o modelo para treinamento**\n",
        "\n",
        "Neste exemplo, utilizamos a \"binary_crossentropy\" como função de perda (\"loss function\"), e não a \"categorical cross entropy\".\n",
        "\n",
        "- Em \"optimizer\", utilizamos um otimizador adaptativo. As outras opções disponíveis podem ser utilizadas aqui.\n",
        "\n",
        "- Desejamos saber a precisão do modelo enquanto o treinamos. Para isso, passamos \"accuracy\" como parâmetro de compilamento do modelo.\n"
      ],
      "metadata": {
        "id": "3TygEjOXw9Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  loss='binary_crossentropy',\n",
        "  optimizer='rmsprop',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "qomVvnpfx1YW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Treinar o modelo**\n",
        "\n",
        "- Utilizamos o método **.fit** para treinar o modelo.\n",
        "- **O modelo treinado ficará armazenado no objeto r** definido a seguir."
      ],
      "metadata": {
        "id": "TCUREOy1yHiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training model...')\n",
        "r = model.fit(\n",
        "  data,\n",
        "  targets,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=VALIDATION_SPLIT\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wutstPIgyDid",
        "outputId": "50433a2d-61cf-4c9a-b9bd-d36370b3e767"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "Epoch 1/10\n",
            "998/998 [==============================] - 26s 14ms/step - loss: 0.0849 - accuracy: 0.9784 - val_loss: 0.0731 - val_accuracy: 0.9941\n",
            "Epoch 2/10\n",
            "998/998 [==============================] - 13s 13ms/step - loss: 0.0675 - accuracy: 0.9907 - val_loss: 0.0694 - val_accuracy: 0.9792\n",
            "Epoch 3/10\n",
            "998/998 [==============================] - 14s 14ms/step - loss: 0.0630 - accuracy: 0.9928 - val_loss: 0.0700 - val_accuracy: 0.9939\n",
            "Epoch 4/10\n",
            "998/998 [==============================] - 14s 14ms/step - loss: 0.0597 - accuracy: 0.9935 - val_loss: 0.0722 - val_accuracy: 0.9941\n",
            "Epoch 5/10\n",
            "998/998 [==============================] - 14s 14ms/step - loss: 0.0572 - accuracy: 0.9938 - val_loss: 0.0725 - val_accuracy: 0.9937\n",
            "Epoch 6/10\n",
            "998/998 [==============================] - 14s 14ms/step - loss: 0.0554 - accuracy: 0.9939 - val_loss: 0.0714 - val_accuracy: 0.9941\n",
            "Epoch 7/10\n",
            "998/998 [==============================] - 14s 14ms/step - loss: 0.0537 - accuracy: 0.9937 - val_loss: 0.0726 - val_accuracy: 0.9940\n",
            "Epoch 8/10\n",
            "998/998 [==============================] - 14s 14ms/step - loss: 0.0525 - accuracy: 0.9935 - val_loss: 0.0844 - val_accuracy: 0.9941\n",
            "Epoch 9/10\n",
            "998/998 [==============================] - 14s 14ms/step - loss: 0.0518 - accuracy: 0.9934 - val_loss: 0.0889 - val_accuracy: 0.9930\n",
            "Epoch 10/10\n",
            "998/998 [==============================] - 13s 14ms/step - loss: 0.0507 - accuracy: 0.9937 - val_loss: 0.0908 - val_accuracy: 0.9922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note a estrutura de uma rede neural simples em Keras:\n",
        "\n",
        "```\n",
        "#Camada de entrada e camadas ocultas: utilize para cada uma delas o comando abaixo, onde N_NEURONIOS representa o total de neurônios utilizados\n",
        "x = Dense(N_NEURONIOS, activation=\"relu\")(input)\n",
        "\n",
        "#Camada de saída:\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "#Definição do modelo:\n",
        "model = Model(inputs=input, outputs=x)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "model.fit(X, y, n_epochs=100)\n",
        "```\n",
        "- \"Activation\" (função de ativação): \"relu\"; \"sigmoid\"; ou \"tanh\";\n",
        "- Saída x = Dense(1, activation=\"sigmoid\")(x): **aqui, o primeiro argumento é o total de variáveis de saída.** Se tivermos uma única saída (resposta única), o primeiro argumento será 1. No caso da classificação de toxicidade, estamos trabalhando com 6 saídas. **De forma mais genérica, o número de saídas é a dimensão da lista de rótulos,** razão pela qual usamos como input: **\"len(possible_labels)\"**.\n",
        "- \"loss\", \"optimizer\" e \"epochs\" são hiperparâmetros das redes neurais, e podem ser modificados até se encontrar a melhor combinação deles.\n",
        "- **\"epochs\": quantidade de vezes em que todo o dataset será utilizado na backpropagation**;\n",
        "- Número de camadas da rede neural simples: será igual à quantidade de operações \"Dense\" aplicadas.\n",
        "\n",
        "Note que, n**o caso da CNN, além das camadas \"Dense\" finais, temos as camadas de convolução e de agrupamento, de modo que o total de camadas não pode ser tomado como igual à quantidade de operações \"Dense\"**."
      ],
      "metadata": {
        "id": "j2IbsVLu0_QR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Salvar modelo treinado no Google Drive para re-importá-lo futuramente (ou baixá-lo no ambiente offline)**\n",
        "\n",
        "Aqui, forneça o mesmo endereço da pasta na qual os arquivos das bases de dados foram salvos. Assim, o modelo ficará salvo na mesma pasta, facilitando sua localização.\n",
        "\n",
        "- Voltando ao início deste notebook, vemos que a pasta utilizada como exemplo tem o endereço: /content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/"
      ],
      "metadata": {
        "id": "jskuFuaU5QtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_adress = \"/content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/\""
      ],
      "metadata": {
        "id": "28aBSXWa59ww"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dill\n",
        "\n",
        "#Nosso modelo foi gerado com a denominação \"r\", como vimos acima.\n",
        "\n",
        "#Definicao do endereço e nome do novo arquivo:\n",
        "file_address = folder_adress + \"obtained_model.dill\"\n",
        "#file_address armazena o local em que sera salvo o modelo: o endereço da pasta foi concatenado\n",
        "#ao nome e extensão desejados para o arquivo.\n",
        "#note que o arquivo gerado se chama obtained_model.dill\n",
        "#o dill permite salvar em qualquer extensao (pkl, sav, pmml, ...)\n",
        "\n",
        "dill.dump(r, open(file_address, 'wb'))\n",
        "#aqui, modifique \"r\" pelo nome do modelo declarado, caso seja outro o nome utilizado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAyummsK5g27",
        "outputId": "14121db6-ea35-4390-955e-cb7520cae3f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://162df6f5-5557-48d8-b21a-9183b53e4d3f/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reimportar modelo pré-treinado**\n",
        "\n",
        "Para reimportar o modelo, basta seguir o código abaixo (ajuste-o de acordo com a pasta do drive na qual está salvo o modelo obtido anteriormente) - basta substituir o valor de \"file_address\" pelo endereço correto"
      ],
      "metadata": {
        "id": "lHxSHZ4Q6_qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dill\n",
        "\n",
        "file_address = \"/content/drive/MyDrive/Advanced NLP/Lesson 1 - convolutional neural networks/obtained_model.dill\"\n",
        "\n",
        "loaded_model = dill.load(open(file_address, 'rb'))\n",
        "\n",
        "#Agora o modelo carregado  recebe o nome de loaded_model\n",
        "#todos os campos que recebiam o nome do modelo devem ter o nome substituído para loaded_model\n",
        "#você também pode modificar o nome loaded_model para um nome de seu interesse. Por exemplo:\n",
        "#r = dill.load(open(file_address, 'rb')) fará o modelo ser carregado com o nome r\n",
        "\n",
        "#ATENÇÃO: Caso já haja um modelo 1 com o nome escolhido para carregar este modelo 2, o modelo 1 deixará de existir, \n",
        "#sendo substituído pelo modelo 2 carregado."
      ],
      "metadata": {
        "id": "ct-qKMQJ-K5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plotar gráfico da função de perda**"
      ],
      "metadata": {
        "id": "2v8Euvqm_YQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot some data\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "aTqvbIRw_eZj",
        "outputId": "5b2aff66-f2e2-4371-d2b7-4b2d54ed06fc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plotar gráfico da precisão**"
      ],
      "metadata": {
        "id": "p8p5OygY_iaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracies\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Ss9D42nE_rsb",
        "outputId": "7a40e479-6014-44fa-f50d-e97804ccd967"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imprimir valor da métrica AUC**"
      ],
      "metadata": {
        "id": "9A73KOVn_xLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the mean AUC over each label\n",
        "p = model.predict(data)\n",
        "aucs = []\n",
        "for j in range(6):\n",
        "    auc = roc_auc_score(targets[:,j], p[:,j])\n",
        "    aucs.append(auc)\n",
        "print(np.mean(aucs))\n"
      ],
      "metadata": {
        "id": "au3b5YMqP54l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3b6faa-f735-45e6-974c-5a67adc8b268"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9754983130947413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente, realizamos uma previsão utilizando o modelo, e **utilizamos um loop para percorrer cada uma das 6 camadas da rede neural construída**.\n",
        "\n",
        "- No caso, são as colunas em \"targets\" e \"predictions\".\n",
        "- Para cada coluna, calculamos a métrica AUC e, ao fim, tomamos o valor médio das 6 métricas obtidas."
      ],
      "metadata": {
        "id": "CnSNq6SWANOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Também **poderíamos ter dividido os dados em um conjunto de treino e um conjunto de teste**."
      ],
      "metadata": {
        "id": "hf-OOFrRA7JN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embora tanto a precisão quanto a métrica AUC sejam bastante elevadas, em 0,97, as curvas obtidas, em especial a do gráfico da função de perdas (que mostra um descasamento das curvas), **indicam a presença de algum grau de overfitting (sobreajuste) dos dados**.\n",
        "- Assim, além de modificação dos hiperparâmetros, pode ser realmente interessante realizar a divisão em treino e teste.\n",
        "- A vantagem da abordagem empregada é que o método **.fit **de Keras realiza um split automático de dados e nos força a enxergar toda a informação simultaneamente. O problema é que, **devido ao overfitting, a capacidade de generalização e realização de previsões deste modelo pode acabar comprometid**a."
      ],
      "metadata": {
        "id": "OhiZXgj9BpvF"
      }
    }
  ]
}